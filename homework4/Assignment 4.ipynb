{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azuma\\AppData\\Local\\Temp\\ipykernel_41472\\415712182.py:10: DeprecationWarning: setConfidenceThreshold() is deprecated, Use 'initialConfig.setConfidenceThreshold()' instead\n",
      "  stereo.setConfidenceThreshold(200)\n",
      "C:\\Users\\azuma\\AppData\\Local\\Temp\\ipykernel_41472\\415712182.py:17: DeprecationWarning: RGB is deprecated, use CAM_A or address camera by name instead.\n",
      "  camRgb.setBoardSocket(dai.CameraBoardSocket.RGB)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "setResolution(): incompatible function arguments. The following argument types are supported:\n    1. (self: depthai.node.ColorCamera, resolution: depthai.ColorCameraProperties.SensorResolution) -> None\n\nInvoked with: <depthai.node.ColorCamera object at 0x0000020FCBE78270>, 1920, 1080",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m camRgb \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mcreateColorCamera()\n\u001b[0;32m     17\u001b[0m camRgb\u001b[38;5;241m.\u001b[39msetBoardSocket(dai\u001b[38;5;241m.\u001b[39mCameraBoardSocket\u001b[38;5;241m.\u001b[39mRGB)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mcamRgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetResolution\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1920\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1080\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Set resolution to 1920x1080\u001b[39;00m\n\u001b[0;32m     19\u001b[0m camRgb\u001b[38;5;241m.\u001b[39msetInterleaved(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m camRgb\u001b[38;5;241m.\u001b[39msetColorOrder(dai\u001b[38;5;241m.\u001b[39mColorCameraProperties\u001b[38;5;241m.\u001b[39mColorOrder\u001b[38;5;241m.\u001b[39mRGB)\n",
      "\u001b[1;31mTypeError\u001b[0m: setResolution(): incompatible function arguments. The following argument types are supported:\n    1. (self: depthai.node.ColorCamera, resolution: depthai.ColorCameraProperties.SensorResolution) -> None\n\nInvoked with: <depthai.node.ColorCamera object at 0x0000020FCBE78270>, 1920, 1080"
     ]
    }
   ],
   "source": [
    "import depthai as dai\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Pipeline configuration\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "# Configure stereo depth stream\n",
    "stereo = pipeline.createStereoDepth()\n",
    "stereo.setConfidenceThreshold(200)\n",
    "stereo.setLeftRightCheck(False)\n",
    "stereo.setExtendedDisparity(False)\n",
    "stereo.setSubpixel(False)\n",
    "\n",
    "# Configure RGB camera stream\n",
    "camRgb = pipeline.createColorCamera()\n",
    "camRgb.setBoardSocket(dai.CameraBoardSocket.RGB)\n",
    "camRgb.setResolution(1920, 1080)  # Set resolution to 1920x1080\n",
    "camRgb.setInterleaved(False)\n",
    "camRgb.setColorOrder(dai.ColorCameraProperties.ColorOrder.RGB)\n",
    "\n",
    "# Link streams\n",
    "stereo.depth.link(camRgb.inputControl)\n",
    "\n",
    "# Create output queues\n",
    "depthQueue = pipeline.createXLinkOut()\n",
    "depthQueue.setStreamName(\"depth\")\n",
    "\n",
    "rgbQueue = pipeline.createXLinkOut()\n",
    "rgbQueue.setStreamName(\"rgb\")\n",
    "\n",
    "# Connect to the device\n",
    "with dai.Device(pipeline) as device:\n",
    "    # Output queues\n",
    "    depthQueue = device.getOutputQueue(name=\"depth\", maxSize=1, blocking=False)\n",
    "    rgbQueue = device.getOutputQueue(name=\"rgb\", maxSize=1, blocking=False)\n",
    "\n",
    "    # Initialize object tracker\n",
    "    tracker = cv2.TrackerCSRT_create()\n",
    "\n",
    "    # Main loop\n",
    "    while True:\n",
    "        # Get frames from the Oak-D camera\n",
    "        depthFrame = depthQueue.get().getFrame()\n",
    "        rgbFrame = rgbQueue.get().getCvFrame()\n",
    "\n",
    "        # Object detection and tracking (placeholder)\n",
    "        # Here, you can implement your object detection and tracking algorithm\n",
    "        # For demonstration, we'll use a dummy bounding box\n",
    "        bbox = (100, 100, 200, 200)  # Format: (x, y, width, height)\n",
    "\n",
    "        # Initialize tracker with the bounding box in the first frame\n",
    "        if bbox is not None:\n",
    "            tracker.init(rgbFrame, bbox)\n",
    "\n",
    "        # Update tracker in subsequent frames\n",
    "        success, bbox = tracker.update(rgbFrame)\n",
    "\n",
    "        # Draw bounding box around the tracked object\n",
    "        if success:\n",
    "            x, y, w, h = [int(coord) for coord in bbox]\n",
    "            cv2.rectangle(rgbFrame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Stereo vision and depth estimation (placeholder)\n",
    "        # Here, you can implement stereo vision techniques to estimate depth\n",
    "        # For demonstration, we'll use a dummy depth map\n",
    "        depth_map = np.zeros_like(rgbFrame)  # Placeholder for depth map\n",
    "\n",
    "        # Dimension estimation (placeholder)\n",
    "        # Once an object is detected and tracked, estimate its dimensions using the depth information\n",
    "\n",
    "        # Display the frames with detected objects and dimensions\n",
    "        cv2.imshow('RGB Camera', rgbFrame)\n",
    "        cv2.imshow('Depth Map', depth_map)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release the camera and close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "## Question 2\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "import depthai as dai\n",
    "from slam import process\n",
    "from display import Display\n",
    "from pointmap import PointMap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azuma\\AppData\\Local\\Temp\\ipykernel_35508\\2085936821.py:13: DeprecationWarning: RGB is deprecated, use CAM_A or address camera by name instead.\n",
      "  camRgb.setBoardSocket(dai.CameraBoardSocket.RGB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected cameras:  [<CameraBoardSocket.CAM_A: 0>, <CameraBoardSocket.CAM_B: 1>, <CameraBoardSocket.CAM_C: 2>]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a pipeline\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "# Define a source - color camera\n",
    "camRgb = pipeline.createColorCamera()\n",
    "camRgb.setBoardSocket(dai.CameraBoardSocket.RGB)\n",
    "camRgb.setResolution(dai.ColorCameraProperties.SensorResolution.THE_4_K)\n",
    "camRgb.setVideoSize(1000, 1000)\n",
    "camRgb.setInterleaved(False)\n",
    "camRgb.setColorOrder(dai.ColorCameraProperties.ColorOrder.RGB)\n",
    "\n",
    "# Create outputs\n",
    "xoutRgb = pipeline.createXLinkOut()\n",
    "xoutRgb.setStreamName(\"rgb\")\n",
    "camRgb.preview.link(xoutRgb.input)\n",
    "\n",
    "xoutRgbVideo = pipeline.createXLinkOut()\n",
    "xoutRgbVideo.setStreamName(\"video\")\n",
    "xoutRgbVideo.input.setBlocking(False)\n",
    "xoutRgbVideo.input.setQueueSize(1)\n",
    "camRgb.video.link(xoutRgbVideo.input)\n",
    "\n",
    "# Create objects for point mapping and display\n",
    "pmap = PointMap()\n",
    "display = Display()\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "visualizer = o3d.visualization.Visualizer()\n",
    "visualizer.create_window(window_name=\"3D plot\", width=960, height=540)\n",
    "\n",
    "# Connect to the device\n",
    "with dai.Device() as device:\n",
    "    print('Connected cameras: ', device.getConnectedCameras())\n",
    "    device.startPipeline(pipeline)\n",
    "\n",
    "    # Output queues\n",
    "    qRgb = device.getOutputQueue(name=\"rgb\", maxSize=30, blocking=False)\n",
    "    out = device.getOutputQueue(name=\"video\", maxSize=1, blocking=False)\n",
    "\n",
    "    while True:\n",
    "        frame = qRgb.get()\n",
    "        output = out.get()\n",
    "        frame = output.getCvFrame()\n",
    "\n",
    "        img, tripoints, kpts, matches = process(frame)\n",
    "        xyz = pmap.collect_points(tripoints)\n",
    "\n",
    "        if kpts is not None or matches is not None:\n",
    "            display.display_points2d(frame, kpts, matches)\n",
    "\n",
    "        display.display_vid(frame)\n",
    "\n",
    "        if xyz is not None:\n",
    "            display.display_points3d(xyz, pcd, visualizer)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
