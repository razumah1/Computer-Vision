{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assignment 1\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Queston 1\n",
    "\"The calibration matrix from performing the camera calibration using Matlab's Computer Vision Toolbox is defined below.\"\n",
    "\n",
    "k = [[1341.88563669822,\t0,\t1024.14808411592],\n",
    "     [0,\t1349.70698899083,\t609.383415036218],\n",
    "     [0,\t0,\t1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azuma\\AppData\\Local\\Temp\\ipykernel_13300\\1886558798.py:24: DeprecationWarning: RGB is deprecated, use CAM_A or address camera by name instead.\n",
      "  camRgb.setBoardSocket(dai.CameraBoardSocket.RGB)\n",
      "C:\\Users\\azuma\\AppData\\Local\\Temp\\ipykernel_13300\\1886558798.py:46: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  int_corners = np.int0(corners)\n",
      "C:\\Users\\azuma\\AppData\\Local\\Temp\\ipykernel_13300\\1886558798.py:69: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)\n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "import cv2\n",
    "import depthai as dai\n",
    "from object_detector import *\n",
    "import numpy as np\n",
    "\n",
    "# Load Aruco detector\n",
    "parameters = cv2.aruco.DetectorParameters()\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_5X5_50)\n",
    "\n",
    "# Load Object Detector\n",
    "detector = HomogeneousBgDetector()\n",
    "\n",
    "# Pipeline initialization\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "# Define the DepthAI camera\n",
    "camRgb = pipeline.create(dai.node.ColorCamera)\n",
    "xout = pipeline.create(dai.node.XLinkOut)\n",
    "\n",
    "xout.setStreamName('video')\n",
    "\n",
    "# Properties\n",
    "camRgb.setBoardSocket(dai.CameraBoardSocket.RGB)\n",
    "camRgb.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "camRgb.setFps(30)\n",
    "\n",
    "# Linking\n",
    "camRgb.video.link(xout.input)\n",
    "\n",
    "# Start the pipeline\n",
    "with dai.Device(pipeline) as device:\n",
    "\n",
    "    # Output queue will be used to get the video frames from the output defined above\n",
    "    q = device.getOutputQueue(name=\"video\", maxSize=30, blocking=True)\n",
    "\n",
    "    while True:\n",
    "        # Get DepthAI camera frame\n",
    "        frame = q.get().getCvFrame()\n",
    "\n",
    "        # Get Aruco marker\n",
    "        corners, _, _ = cv2.aruco.detectMarkers(frame, aruco_dict, parameters=parameters)\n",
    "        if corners:\n",
    "\n",
    "            # Draw polygon around the marker\n",
    "            int_corners = np.int0(corners)\n",
    "            cv2.polylines(frame, int_corners, True, (0, 255, 0), 5)\n",
    "\n",
    "            # Aruco Perimeter\n",
    "            aruco_perimeter = cv2.arcLength(corners[0], True)\n",
    "\n",
    "            # Pixel to cm ratio\n",
    "            pixel_cm_ratio = aruco_perimeter / 20\n",
    "\n",
    "            contours = detector.detect_objects(frame)\n",
    "\n",
    "            # Draw objects boundaries\n",
    "            for cnt in contours:\n",
    "                # Get rect\n",
    "                rect = cv2.minAreaRect(cnt)\n",
    "                (x, y), (w, h), angle = rect\n",
    "\n",
    "                # Get Width and Height of the Objects by applying the Ratio pixel to cm\n",
    "                object_width = w / pixel_cm_ratio\n",
    "                object_height = h / pixel_cm_ratio\n",
    "\n",
    "                # Display rectangle\n",
    "                box = cv2.boxPoints(rect)\n",
    "                box = np.int0(box)\n",
    "\n",
    "                cv2.circle(frame, (int(x), int(y)), 5, (0, 0, 255), -1)\n",
    "                cv2.polylines(frame, [box], True, (255, 0, 0), 2)\n",
    "                cv2.putText(frame, \"Width {} cm\".format(round(object_width, 1)), (int(x - 100), int(y - 20)), cv2.FONT_HERSHEY_PLAIN, 2, (100, 200, 0), 2)\n",
    "                cv2.putText(frame, \"Height {} cm\".format(round(object_height, 1)), (int(x - 100), int(y + 15)), cv2.FONT_HERSHEY_PLAIN, 2, (100, 200, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Image\", frame)\n",
    "        key = cv2.waitKey(1)  \n",
    "        if key == ord('q'):  # 'q' key is pressed\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
